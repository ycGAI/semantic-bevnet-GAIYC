#!/usr/bin/env python3
"""
3Dè¾¹ç•Œæ¡†è½¬ç‚¹äº‘åˆ†å‰²æ ‡ç­¾ç”Ÿæˆå™¨
å°†KITTIæ ¼å¼çš„3Dè¾¹ç•Œæ¡†æ ‡æ³¨è½¬æ¢ä¸ºç‚¹äº‘çº§åˆ«çš„åˆ†å‰²æ ‡ç­¾
åŒæ—¶ç”Ÿæˆè¿‡æ»¤åçš„ç‚¹äº‘æ•°æ®ï¼ˆåªä¿ç•™bboxå†…çš„ç‚¹ï¼‰
"""

import numpy as np
import argparse
import os
from pathlib import Path
import struct
from tqdm import tqdm

# åœ°é¢ç©¿è¶Šæ€§ç±»åˆ«æ˜ å°„
TRAVERSABILITY_CLASSES = {
    1: {'name': 'Traversable', 'label': 1},      # å¯é€šè¡ŒåŒºåŸŸ
    2: {'name': 'Mid-cost', 'label': 2},         # ä¸­ç­‰ä»£ä»·åŒºåŸŸ  
    3: {'name': 'High-cost', 'label': 3},        # é«˜ä»£ä»·åŒºåŸŸ
    4: {'name': 'Barrier', 'label': 4}           # éšœç¢ç‰©/ä¸å¯é€šè¡Œ
}

class BBoxToSegmentationConverter:
    def __init__(self, input_path, output_path, sequence="00"):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            input_path: è¾“å…¥æ•°æ®é›†è·¯å¾„
            output_path: è¾“å‡ºæ•°æ®é›†è·¯å¾„  
            sequence: åºåˆ—å·
        """
        self.input_path = Path(input_path)
        self.output_path = Path(output_path)
        self.sequence = sequence
        
        # è¾“å…¥è·¯å¾„
        if (self.input_path / "sequences" / sequence).exists():
            self.input_sequence_path = self.input_path / "sequences" / sequence
        else:
            self.input_sequence_path = self.input_path
            
        # è¾“å‡ºè·¯å¾„
        self.output_sequence_path = self.output_path / "sequences" / sequence
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.setup_output_directories()
        
        print(f"ğŸ¯ è¾“å…¥è·¯å¾„: {self.input_sequence_path}")
        print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {self.output_sequence_path}")
        
    def setup_output_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        directories = [
            "velodyne",           # è¿‡æ»¤åçš„ç‚¹äº‘
            "labels_needed",             # bboxå†…ç‚¹äº‘å¯¹åº”çš„æ ‡ç­¾
            "semantic_labels",    # å…¨éƒ¨çš„ç‚¹äº‘æ ‡ç­¾
        ]
        
        for dir_name in directories:
            (self.output_sequence_path / dir_name).mkdir(parents=True, exist_ok=True)
        
        print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {self.output_sequence_path}")
    
    def load_point_cloud(self, frame_id):
        """åŠ è½½ç‚¹äº‘æ•°æ®"""
        velodyne_file = self.input_sequence_path / "velodyne" / f"{frame_id:06d}.bin"
        
        if not velodyne_file.exists():
            return None
        
        try:
            points = np.fromfile(velodyne_file, dtype=np.float32).reshape(-1, 4)
            return points
        except Exception as e:
            print(f"âŒ åŠ è½½ç‚¹äº‘å¤±è´¥ {frame_id:06d}: {e}")
            return None
    
    def load_bboxes(self, frame_id):
        """åŠ è½½3Dè¾¹ç•Œæ¡†æ ‡æ³¨"""
        label_file = self.input_sequence_path / "labels" / f"{frame_id:06d}.txt"
        
        if not label_file.exists():
            return []
        
        bboxes = []
        try:
            with open(label_file, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    parts = line.strip().split()
                    if len(parts) >= 15:
                        try:
                            bbox = {
                                'type': int(parts[0]),
                                'truncated': float(parts[1]),
                                'occluded': int(parts[2]),
                                'alpha': float(parts[3]),
                                'bbox_2d': [float(parts[4]), float(parts[5]), 
                                           float(parts[6]), float(parts[7])],
                                'h': float(parts[8]),
                                'w': float(parts[9]),
                                'l': float(parts[10]),
                                'x': float(parts[11]),
                                'y': float(parts[12]),
                                'z': float(parts[13]),
                                'ry': float(parts[14])
                            }
                            
                            if bbox['type'] in TRAVERSABILITY_CLASSES:
                                bboxes.append(bbox)
                            
                        except ValueError as e:
                            print(f"âš ï¸  ç¬¬{line_num}è¡Œè§£æé”™è¯¯: {e}")
                            continue
                            
        except Exception as e:
            print(f"âŒ è¯»å–æ ‡æ³¨æ–‡ä»¶å¤±è´¥: {e}")
            return []
        
        return bboxes
    
    def expand_bbox_vertically(self, bbox, expand_up=0.5, expand_down=0.3):
        """
        åœ¨å‚ç›´æ–¹å‘ä¸Šæ‰©å¤§è¾¹ç•Œæ¡†
        
        Args:
            bbox: åŸå§‹è¾¹ç•Œæ¡†
            expand_up: å‘ä¸Šæ‰©å±•è·ç¦»(ç±³)
            expand_down: å‘ä¸‹æ‰©å±•è·ç¦»(ç±³)
        """
        expanded_bbox = bbox.copy()
        expanded_bbox['h'] = bbox['h'] + expand_up + expand_down
        expanded_bbox['z'] = bbox['z'] - expand_down  # åº•é¢å‘ä¸‹ç§»åŠ¨
        
        return expanded_bbox
    
    def point_in_bbox(self, points, bbox):
        """
        æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨3Dè¾¹ç•Œæ¡†å†…
        
        Args:
            points: ç‚¹äº‘æ•°ç»„ (N, 3) æˆ– (N, 4)
            bbox: è¾¹ç•Œæ¡†å‚æ•°å­—å…¸
            
        Returns:
            mask: å¸ƒå°”æ•°ç»„ï¼ŒTrueè¡¨ç¤ºç‚¹åœ¨è¾¹ç•Œæ¡†å†…
        """
        # æå–ç‚¹çš„3Dåæ ‡
        if points.shape[1] >= 3:
            pts = points[:, :3]
        else:
            raise ValueError("ç‚¹äº‘æ•°æ®è‡³å°‘éœ€è¦3ä¸ªåæ ‡")
        
        # è¾¹ç•Œæ¡†å‚æ•°
        x, y, z = bbox['x'], bbox['y'], bbox['z']
        h, w, l = bbox['h'], bbox['w'], bbox['l']
        ry = bbox['ry']
        
        # å°†ç‚¹è½¬æ¢åˆ°è¾¹ç•Œæ¡†åæ ‡ç³»
        # 1. å¹³ç§»åˆ°è¾¹ç•Œæ¡†ä¸­å¿ƒ
        pts_translated = pts - np.array([x, y, z + h/2])
        
        # 2. ç»•Yè½´æ—‹è½¬ï¼ˆCVATæ ¼å¼ï¼‰
        cos_ry = np.cos(-ry)  # æ³¨æ„ï¼šè¿™é‡Œç”¨è´Ÿè§’åº¦è¿›è¡Œé€†æ—‹è½¬
        sin_ry = np.sin(-ry)
        
        # æ—‹è½¬çŸ©é˜µï¼ˆç»•Yè½´ï¼‰
        R_inv = np.array([
            [cos_ry, 0, sin_ry],
            [0, 1, 0],
            [-sin_ry, 0, cos_ry]
        ])
        
        pts_rotated = pts_translated @ R_inv.T
        
        # 3. æ£€æŸ¥æ˜¯å¦åœ¨è¾¹ç•Œæ¡†èŒƒå›´å†…
        mask_x = np.abs(pts_rotated[:, 0]) <= w / 2
        mask_y = np.abs(pts_rotated[:, 1]) <= l / 2  
        mask_z = np.abs(pts_rotated[:, 2]) <= h / 2
        
        return mask_x & mask_y & mask_z
    
    def process_frame(self, frame_id, expand_up=0.5, expand_down=0.3, priority_order=None, filter_background=True):
        """
        å¤„ç†å•å¸§æ•°æ®ï¼Œç”Ÿæˆåˆ†å‰²æ ‡ç­¾å’Œè¿‡æ»¤ç‚¹äº‘
        
        Args:
            frame_id: å¸§ID
            expand_up: å‘ä¸Šæ‰©å±•è·ç¦»
            expand_down: å‘ä¸‹æ‰©å±•è·ç¦»  
            priority_order: ç±»åˆ«ä¼˜å…ˆçº§é¡ºåºï¼ˆè§£å†³é‡å é—®é¢˜ï¼‰
            filter_background: æ˜¯å¦è¿‡æ»¤èƒŒæ™¯ç‚¹
        """
        # åŠ è½½æ•°æ®
        points = self.load_point_cloud(frame_id)
        bboxes = self.load_bboxes(frame_id)
        
        if points is None:
            print(f"âš ï¸  è·³è¿‡å¸§ {frame_id:06d}: æ— ç‚¹äº‘æ•°æ®")
            return False, {}
            
        if not bboxes:
            print(f"âš ï¸  è·³è¿‡å¸§ {frame_id:06d}: æ— è¾¹ç•Œæ¡†æ ‡æ³¨")
            return False, {}
        
        print(f"ğŸ”„ å¤„ç†å¸§ {frame_id:06d}: {len(points):,} ç‚¹, {len(bboxes)} ä¸ªè¾¹ç•Œæ¡†")
        
        # åˆå§‹åŒ–æ ‡ç­¾ï¼ˆ0è¡¨ç¤ºèƒŒæ™¯/æœªæ ‡æ³¨ï¼‰
        labels = np.zeros(len(points), dtype=np.int32)
        in_any_bbox = np.zeros(len(points), dtype=bool)
        
        # è®¾ç½®ä¼˜å…ˆçº§é¡ºåºï¼š1 < 2 < 3 < 4 ï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        if priority_order is None:
            priority_order = [1, 2, 3, 4]
        
        print(f"   ğŸ† ä¼˜å…ˆçº§é¡ºåº: {' < '.join(map(str, priority_order))} (å³ä¾§ä¼˜å…ˆçº§æ›´é«˜)")
        print(f"   ğŸ—‚ï¸  è¿‡æ»¤æ¨¡å¼: {'è¿‡æ»¤èƒŒæ™¯ç‚¹' if filter_background else 'ä¿ç•™æ‰€æœ‰ç‚¹'}")
        
        # ç»Ÿè®¡æ¯ä¸ªè¾¹ç•Œæ¡†åŒ…å«çš„ç‚¹æ•°ï¼ˆç”¨äºé‡å åˆ†æï¼‰
        bbox_point_counts = {}
        overlap_stats = {}
        
        # æŒ‰ä¼˜å…ˆçº§ä»ä½åˆ°é«˜å¤„ç†è¾¹ç•Œæ¡†ï¼ˆé«˜ä¼˜å…ˆçº§ä¼šè¦†ç›–ä½ä¼˜å…ˆçº§ï¼‰
        sorted_bboxes = sorted(bboxes, key=lambda x: priority_order.index(x['type']) if x['type'] in priority_order else -1)
        
        for i, bbox in enumerate(sorted_bboxes):
            if bbox['type'] not in priority_order:
                continue
                
            # æ‰©å±•è¾¹ç•Œæ¡†
            expanded_bbox = self.expand_bbox_vertically(bbox, expand_up, expand_down)
            
            # æ‰¾åˆ°åœ¨è¾¹ç•Œæ¡†å†…çš„ç‚¹
            mask = self.point_in_bbox(points, expanded_bbox)
            point_count = np.sum(mask)
            
            # ç»Ÿè®¡ä¸å·²æœ‰æ ‡ç­¾çš„é‡å 
            already_labeled_mask = (labels > 0) & mask
            overlap_count = np.sum(already_labeled_mask)
            new_points = point_count - overlap_count
            
            # è®°å½•é‡å ä¿¡æ¯
            if overlap_count > 0:
                overlapped_labels = np.unique(labels[already_labeled_mask])
                overlap_info = []
                for prev_label in overlapped_labels:
                    if prev_label > 0:
                        prev_count = np.sum((labels == prev_label) & mask)
                        prev_name = TRAVERSABILITY_CLASSES[prev_label]['name']
                        overlap_info.append(f"{prev_count} from {prev_label}({prev_name})")
                
                overlap_stats[bbox['type']] = {
                    'total_overlap': overlap_count,
                    'details': overlap_info
                }
            
            # åˆ†é…æ ‡ç­¾ï¼ˆé«˜ä¼˜å…ˆçº§ä¼šè¦†ç›–ä½ä¼˜å…ˆçº§ï¼‰
            labels[mask] = bbox['type']
            in_any_bbox[mask] = True
            
            bbox_point_counts[bbox['type']] = bbox_point_counts.get(bbox['type'], 0) + point_count
            
            class_name = TRAVERSABILITY_CLASSES[bbox['type']]['name']
            priority_level = priority_order.index(bbox['type'])
            
            print(f"   ğŸ“¦ è¾¹ç•Œæ¡† {i+1}: ç±»åˆ« {bbox['type']} ({class_name}), ä¼˜å…ˆçº§ {priority_level}")
            print(f"      åŒ…å«ç‚¹æ•°: {point_count:,}")
            if overlap_count > 0:
                print(f"      é‡å è¦†ç›–: {overlap_count:,} ä¸ªç‚¹ ({', '.join(overlap_stats[bbox['type']]['details'])})")
                print(f"      æ–°å¢ç‚¹æ•°: {new_points:,}")
        
        # ç»Ÿè®¡æœ€ç»ˆæ ‡ç­¾åˆ†å¸ƒ
        unique_labels, counts = np.unique(labels, return_counts=True)
        total_labeled = np.sum(in_any_bbox)
        
        frame_stats = {}
        
        print(f"\n   ğŸ“Š æœ€ç»ˆæ ‡ç­¾ç»Ÿè®¡:")
        for label, count in zip(unique_labels, counts):
            if label == 0:
                if not filter_background:  # åªæœ‰ä¿ç•™èƒŒæ™¯æ—¶æ‰ç»Ÿè®¡
                    print(f"      èƒŒæ™¯: {count:,} ä¸ªç‚¹ ({count/len(points)*100:.1f}%)")
                    frame_stats[0] = count
            else:
                class_name = TRAVERSABILITY_CLASSES.get(label, {}).get('name', f'Class_{label}')
                priority_level = priority_order.index(label) if label in priority_order else -1
                print(f"      {label} ({class_name}): {count:,} ä¸ªç‚¹ ({count/len(points)*100:.1f}%) [ä¼˜å…ˆçº§: {priority_level}]")
                frame_stats[label] = count
        
        print(f"   ğŸ“ˆ æ€»æ ‡æ³¨è¦†ç›–ç‡: {total_labeled:,}/{len(points):,} ({total_labeled/len(points)*100:.1f}%)")
        
        # é‡å ç»Ÿè®¡æ‘˜è¦
        if overlap_stats:
            print(f"\n   ğŸ”„ é‡å å¤„ç†æ‘˜è¦:")
            for class_id, stats in overlap_stats.items():
                class_name = TRAVERSABILITY_CLASSES[class_id]['name']
                print(f"      {class_id} ({class_name}) è¦†ç›–äº† {stats['total_overlap']:,} ä¸ªä½ä¼˜å…ˆçº§ç‚¹")
        
        # ä¿å­˜åˆ†å‰²æ ‡ç­¾
        if filter_background:
            # åªä¿å­˜bboxå†…çš„ç‚¹å’Œæ ‡ç­¾
            filtered_points = points[in_any_bbox]
            filtered_labels = labels[in_any_bbox]
            
            if len(filtered_points) > 0:
                self.save_filtered_pointcloud(frame_id, filtered_points)
                self.save_filtered_labels(frame_id, filtered_labels)
                self.save_segmentation_labels(frame_id, filtered_labels)  # ä¿å­˜è¿‡æ»¤åçš„æ ‡ç­¾
                
                print(f"   ğŸ’¾ ä¿å­˜è¿‡æ»¤åç‚¹äº‘: {len(filtered_points):,} ä¸ªç‚¹ (æ‰€æœ‰ç‚¹éƒ½æœ‰æ ‡ç­¾)")
            else:
                print(f"   âš ï¸  æ²¡æœ‰ç‚¹åœ¨è¾¹ç•Œæ¡†å†…")
        else:
            # ä¿å­˜å®Œæ•´ç‚¹äº‘å’Œå¯¹åº”æ ‡ç­¾
            self.save_filtered_pointcloud(frame_id, points)
            self.save_segmentation_labels(frame_id, labels)  # åŒ…å«èƒŒæ™¯æ ‡ç­¾
            
            # åŒæ—¶ä¿å­˜ä»…æ ‡æ³¨ç‚¹çš„ç‰ˆæœ¬
            if total_labeled > 0:
                labeled_points = points[in_any_bbox]
                labeled_labels = labels[in_any_bbox]
                self.save_filtered_labels(frame_id, labeled_labels)
                
                print(f"   ğŸ’¾ ä¿å­˜å®Œæ•´ç‚¹äº‘: {len(points):,} ä¸ªç‚¹ (åŒ…å« {len(points)-total_labeled:,} ä¸ªèƒŒæ™¯ç‚¹)")
                print(f"   ğŸ’¾ ä¿å­˜æ ‡æ³¨ç‚¹: {total_labeled:,} ä¸ªç‚¹ (æ— èƒŒæ™¯)")
            else:
                print(f"   âš ï¸  æ²¡æœ‰ç‚¹åœ¨è¾¹ç•Œæ¡†å†…")
        
        return True, frame_stats
    
    def save_segmentation_labels(self, frame_id, labels):
        """ä¿å­˜å®Œæ•´ç‚¹äº‘çš„åˆ†å‰²æ ‡ç­¾"""
        label_file = self.output_sequence_path / "semantic_labels" / f"{frame_id:06d}.label"
        
        # è½¬æ¢ä¸ºuint32æ ¼å¼ä¿å­˜
        labels_uint32 = labels.astype(np.uint32)
        labels_uint32.tofile(label_file)
    
    def save_filtered_pointcloud(self, frame_id, points):
        """ä¿å­˜è¿‡æ»¤åçš„ç‚¹äº‘"""
        velodyne_file = self.output_sequence_path / "velodyne" / f"{frame_id:06d}.bin"
        points.astype(np.float32).tofile(velodyne_file)
    
    def save_filtered_labels(self, frame_id, labels):
        """ä¿å­˜è¿‡æ»¤åç‚¹äº‘å¯¹åº”çš„æ ‡ç­¾"""
        label_file = self.output_sequence_path / "labels" / f"{frame_id:06d}.label"
        labels.astype(np.uint32).tofile(label_file)
    
    def convert_dataset(self, expand_up=0.5, expand_down=0.3, priority_order=None, filter_background=True):
        """è½¬æ¢æ•´ä¸ªæ•°æ®é›†"""
        print(f"ğŸš€ å¼€å§‹è½¬æ¢æ•°æ®é›†")
        print(f"ğŸ“ å‚ç›´æ‰©å±•: å‘ä¸Š {expand_up}m, å‘ä¸‹ {expand_down}m")
        print(f"ğŸ—‚ï¸  è¿‡æ»¤æ¨¡å¼: {'è¿‡æ»¤èƒŒæ™¯ç‚¹' if filter_background else 'ä¿ç•™æ‰€æœ‰ç‚¹'}")
        
        if priority_order is None:
            priority_order = [1, 2, 3, 4]
            
        print(f"ğŸ† ç±»åˆ«ä¼˜å…ˆçº§: {' < '.join(map(str, priority_order))} (æ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜)")
        
        # æ‰¾åˆ°æ‰€æœ‰ç‚¹äº‘æ–‡ä»¶
        velodyne_files = list(self.input_sequence_path.glob("velodyne/*.bin"))
        velodyne_files.sort()
        
        if not velodyne_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç‚¹äº‘æ–‡ä»¶")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(velodyne_files)} ä¸ªç‚¹äº‘æ–‡ä»¶")
        
        success_count = 0
        failed_count = 0
        
        # å…¨å±€ç»Ÿè®¡
        global_stats = {0: 0}  # èƒŒæ™¯
        for class_id in TRAVERSABILITY_CLASSES.keys():
            global_stats[class_id] = 0
        
        total_points = 0
        total_labeled_points = 0
        
        # å¤„ç†æ¯ä¸€å¸§
        for velodyne_file in tqdm(velodyne_files, desc="è½¬æ¢è¿›åº¦"):
            frame_id = int(velodyne_file.stem)
            
            try:
                success, frame_stats = self.process_frame(frame_id, expand_up, expand_down, priority_order, filter_background)
                if success:
                    success_count += 1
                    # ç´¯åŠ ç»Ÿè®¡
                    for label, count in frame_stats.items():
                        global_stats[label] = global_stats.get(label, 0) + count
                        if label > 0:
                            total_labeled_points += count
                        total_points += count
                else:
                    failed_count += 1
            except Exception as e:
                print(f"âŒ å¤„ç†å¸§ {frame_id:06d} å¤±è´¥: {e}")
                failed_count += 1
        
        print(f"\nâœ… è½¬æ¢å®Œæˆ!")
        print(f"   æˆåŠŸ: {success_count} å¸§")
        print(f"   å¤±è´¥: {failed_count} å¸§")
        print(f"   è¾“å‡ºç›®å½•: {self.output_sequence_path}")
        
        # æ‰“å°å…¨å±€ç»Ÿè®¡
        print(f"\nğŸ“Š å…¨æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   æ€»ç‚¹æ•°: {total_points:,}")
        print(f"   æ ‡æ³¨ç‚¹æ•°: {total_labeled_points:,} ({total_labeled_points/total_points*100:.1f}%)")
        if not filter_background:
            print(f"   èƒŒæ™¯ç‚¹æ•°: {global_stats[0]:,} ({global_stats[0]/total_points*100:.1f}%)")
        
        print(f"\nğŸ·ï¸  å„ç±»åˆ«ç‚¹æ•°ç»Ÿè®¡:")
        for class_id in sorted(TRAVERSABILITY_CLASSES.keys()):
            count = global_stats.get(class_id, 0)
            class_name = TRAVERSABILITY_CLASSES[class_id]['name']
            percentage = count / total_points * 100 if total_points > 0 else 0
            labeled_percentage = count / total_labeled_points * 100 if total_labeled_points > 0 else 0
            priority_level = priority_order.index(class_id) if class_id in priority_order else -1
            
            print(f"   {class_id} ({class_name}): {count:,} ä¸ªç‚¹")
            print(f"      å æ€»ç‚¹æ•°: {percentage:.2f}%")
            print(f"      å æ ‡æ³¨ç‚¹æ•°: {labeled_percentage:.2f}%")
            print(f"      ä¼˜å…ˆçº§: {priority_level}")
            print()
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_summary_report(global_stats, total_points, total_labeled_points, priority_order, filter_background)
        
        return global_stats
    
    def generate_summary_report(self, global_stats, total_points, total_labeled_points, priority_order, filter_background):
        """ç”Ÿæˆè½¬æ¢æ€»ç»“æŠ¥å‘Š"""
        report_file = self.output_sequence_path / "conversion_report.txt"
        
        # ç»Ÿè®¡è¾“å‡ºæ–‡ä»¶
        velodyne_files = list((self.output_sequence_path / "velodyne").glob("*.bin"))
        semantic_files = list((self.output_sequence_path / "semantic_labels").glob("*.label"))
        filtered_files = list((self.output_sequence_path / "labels").glob("*.label"))
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("3Dè¾¹ç•Œæ¡†åˆ°ç‚¹äº‘åˆ†å‰²è½¬æ¢æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"è¾“å…¥è·¯å¾„: {self.input_sequence_path}\n")
            f.write(f"è¾“å‡ºè·¯å¾„: {self.output_sequence_path}\n")
            f.write(f"åºåˆ—å·: {self.sequence}\n\n")
            
            f.write("è¾“å‡ºæ–‡ä»¶ç»Ÿè®¡:\n")
            f.write(f"  è¿‡æ»¤åç‚¹äº‘: {len(velodyne_files)} ä¸ªæ–‡ä»¶\n")
            f.write(f"  å®Œæ•´åˆ†å‰²æ ‡ç­¾: {len(semantic_files)} ä¸ªæ–‡ä»¶\n")
            f.write(f"  è¿‡æ»¤åˆ†å‰²æ ‡ç­¾: {len(filtered_files)} ä¸ªæ–‡ä»¶\n\n")
            
            f.write("å¤„ç†æ¨¡å¼:\n")
            f.write(f"  è¿‡æ»¤èƒŒæ™¯ç‚¹: {'æ˜¯' if filter_background else 'å¦'}\n")
            f.write(f"  è¾“å‡ºç±»å‹: {'ä»…æ ‡æ³¨ç‚¹' if filter_background else 'å®Œæ•´ç‚¹äº‘+èƒŒæ™¯'}\n\n")
            
            f.write("ä¼˜å…ˆçº§è®¾ç½®:\n")
            f.write(f"  ä¼˜å…ˆçº§é¡ºåº: {' < '.join(map(str, priority_order))} (æ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜)\n")
            f.write(f"  é‡å å¤„ç†: é«˜ä¼˜å…ˆçº§æ ‡ç­¾è¦†ç›–ä½ä¼˜å…ˆçº§æ ‡ç­¾\n\n")
            
            f.write("ç±»åˆ«æ˜ å°„:\n")
            for class_id, info in TRAVERSABILITY_CLASSES.items():
                priority_level = priority_order.index(class_id) if class_id in priority_order else -1
                f.write(f"  {class_id}: {info['name']} (ä¼˜å…ˆçº§: {priority_level})\n")
            f.write(f"  0: èƒŒæ™¯/æœªæ ‡æ³¨\n\n")
            
            f.write("å…¨æ•°æ®é›†ç‚¹äº‘ç»Ÿè®¡:\n")
            f.write(f"  æ€»ç‚¹æ•°: {total_points:,}\n")
            f.write(f"  æ ‡æ³¨ç‚¹æ•°: {total_labeled_points:,} ({total_labeled_points/total_points*100:.2f}%)\n")
            if not filter_background:
                f.write(f"  èƒŒæ™¯ç‚¹æ•°: {global_stats[0]:,} ({global_stats[0]/total_points*100:.2f}%)\n")
            f.write("\n")
            
            f.write("å„ç±»åˆ«è¯¦ç»†ç»Ÿè®¡:\n")
            for class_id in sorted(TRAVERSABILITY_CLASSES.keys()):
                count = global_stats.get(class_id, 0)
                class_name = TRAVERSABILITY_CLASSES[class_id]['name']
                percentage = count / total_points * 100 if total_points > 0 else 0
                labeled_percentage = count / total_labeled_points * 100 if total_labeled_points > 0 else 0
                priority_level = priority_order.index(class_id) if class_id in priority_order else -1
                
                f.write(f"  ç±»åˆ« {class_id} ({class_name}):\n")
                f.write(f"    ç‚¹æ•°: {count:,}\n")
                f.write(f"    å æ€»ç‚¹æ•°: {percentage:.2f}%\n")
                f.write(f"    å æ ‡æ³¨ç‚¹æ•°: {labeled_percentage:.2f}%\n")
                f.write(f"    ä¼˜å…ˆçº§: {priority_level}\n\n")
            
            f.write("æ•°æ®ä½¿ç”¨è¯´æ˜:\n")
            if filter_background:
                f.write("  1. semantic_labels/*.label - è¿‡æ»¤åç‚¹äº‘çš„åˆ†å‰²æ ‡ç­¾ (æ— èƒŒæ™¯)\n")
                f.write("  2. velodyne/*.bin - è¿‡æ»¤åçš„ç‚¹äº‘ (åªåŒ…å«bboxå†…çš„ç‚¹)\n")
                f.write("  3. labels/*.label - è¿‡æ»¤åç‚¹äº‘å¯¹åº”çš„æ ‡ç­¾ (ä¸semantic_labelsç›¸åŒ)\n")
                f.write("  4. æ‰€æœ‰ä¿ç•™çš„ç‚¹éƒ½æœ‰éé›¶æ ‡ç­¾ (1-4)\n")
            else:
                f.write("  1. semantic_labels/*.label - å®Œæ•´ç‚¹äº‘çš„åˆ†å‰²æ ‡ç­¾ (åŒ…å«èƒŒæ™¯)\n")
                f.write("  2. velodyne/*.bin - å®Œæ•´çš„åŸå§‹ç‚¹äº‘\n")
                f.write("  3. labels/*.label - è¿‡æ»¤åç‚¹äº‘å¯¹åº”çš„æ ‡ç­¾ (åªæœ‰bboxå†…çš„ç‚¹)\n")
                f.write("  4. æ ‡ç­¾æ ¼å¼: 0=èƒŒæ™¯, 1-4=ç©¿è¶Šæ€§ç±»åˆ«\n")
            f.write("  5. æ ‡ç­¾æ ¼å¼: uint32, æ¯ä¸ªç‚¹ä¸€ä¸ªæ ‡ç­¾å€¼\n")
        
        print(f"ğŸ“ ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # åŒæ—¶ç”ŸæˆCSVæ ¼å¼çš„ç»Ÿè®¡æ–‡ä»¶
        csv_file = self.output_sequence_path / "class_statistics.csv"
        with open(csv_file, 'w') as f:
            f.write("class_id,class_name,point_count,total_percentage,labeled_percentage,priority_level\n")
            if not filter_background:
                f.write(f"0,Background,{global_stats[0]},{global_stats[0]/total_points*100:.2f},-,-\n")
            
            for class_id in sorted(TRAVERSABILITY_CLASSES.keys()):
                count = global_stats.get(class_id, 0)
                class_name = TRAVERSABILITY_CLASSES[class_id]['name']
                percentage = count / total_points * 100 if total_points > 0 else 0
                labeled_percentage = count / total_labeled_points * 100 if total_labeled_points > 0 else 0
                priority_level = priority_order.index(class_id) if class_id in priority_order else -1
                
                f.write(f"{class_id},{class_name},{count},{percentage:.2f},{labeled_percentage:.2f},{priority_level}\n")
        
        print(f"ğŸ“Š ç”ŸæˆCSVç»Ÿè®¡: {csv_file}")


def main():
    parser = argparse.ArgumentParser(description="3Dè¾¹ç•Œæ¡†è½¬ç‚¹äº‘åˆ†å‰²æ ‡ç­¾ç”Ÿæˆå™¨")
    parser.add_argument("input_path", help="è¾“å…¥æ•°æ®é›†è·¯å¾„")
    parser.add_argument("output_path", help="è¾“å‡ºæ•°æ®é›†è·¯å¾„")
    parser.add_argument("-s", "--sequence", default="00", help="åºåˆ—å· (é»˜è®¤: 00)")
    parser.add_argument("--expand-up", type=float, default=0.5, 
                       help="è¾¹ç•Œæ¡†å‘ä¸Šæ‰©å±•è·ç¦»(ç±³) (é»˜è®¤: 0.5)")
    parser.add_argument("--expand-down", type=float, default=0.3,
                       help="è¾¹ç•Œæ¡†å‘ä¸‹æ‰©å±•è·ç¦»(ç±³) (é»˜è®¤: 0.3)")
    parser.add_argument("--priority", nargs='+', type=int, default=[1, 2, 3, 4],
                       help="ç±»åˆ«ä¼˜å…ˆçº§é¡ºåº (é»˜è®¤: 1 2 3 4)")
    parser.add_argument("--filter-background", action="store_true", default=True,
                       help="è¿‡æ»¤èƒŒæ™¯ç‚¹ï¼Œåªä¿ç•™bboxå†…çš„ç‚¹ (é»˜è®¤)")
    parser.add_argument("--keep-all", action="store_true",
                       help="ä¿ç•™æ‰€æœ‰ç‚¹ï¼ŒåŒ…æ‹¬èƒŒæ™¯ç‚¹")
    
    args = parser.parse_args()
    
    # å¤„ç†äº’æ–¥å‚æ•°
    if args.keep_all:
        args.filter_background = False
    
    try:
        converter = BBoxToSegmentationConverter(
            args.input_path, 
            args.output_path, 
            args.sequence
        )
        
        converter.convert_dataset(
            expand_up=args.expand_up,
            expand_down=args.expand_down,
            priority_order=args.priority,
            filter_background=args.filter_background
        )
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­è½¬æ¢")
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()